apiVersion: v1
kind: ConfigMap
metadata:
  name: thehive-config
  namespace: thehive
data:
  application.conf: |-
    #play.http.secret.key="ThehiveTestPassword"
    # JanusGraph
    db {
      provider: janusgraph
      janusgraph {
        storage {
          backend: cql
          hostname: ["cassandra"]
          cql {
            cluster-name: thp       # cluster name
            keyspace: thehive           # name of the keyspace
            replication-factor: 1 # 3 is recommended. Number of replica.
            read-consistency-level: ONE
            write-consistency-level: ONE
          }
        }
        # Index configuration
        index {
          search {
            backend: lucene
            directory: /opt/thp/thehive/index
          }
        }
      }
    }
    storage {
      provider: localfs
      localfs.location: /opt/thp/thehive/data
    }
    play.http.parser.maxDiskBuffer: 50MB
    
  logback.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration debug="false">
    
        <conversionRule conversionWord="coloredLevel"
            converterClass="play.api.libs.logback.ColoredLevel" />
            
        <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
            <file>${application.home:-.}/logs/application.log</file>
            <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">
                <fileNamePattern>${application.home:-.}/logs/application.%i.log.zip</fileNamePattern>
                <minIndex>1</minIndex>
                <maxIndex>10</maxIndex>
            </rollingPolicy>
            <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
                <maxFileSize>10MB</maxFileSize>
            </triggeringPolicy>
            <encoder>
                <pattern>%date [%level] from %logger in %thread - %message%n%xException</pattern>
            </encoder>
        </appender>
        
        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder>
                <pattern>%coloredLevel %logger{15} - %message%n%xException{10}
                </pattern>
            </encoder>
        </appender>
        
        <appender name="ASYNCFILE" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="FILE" />
        </appender>
        
        <appender name="ASYNCSTDOUT" class="ch.qos.logback.classic.AsyncAppender">
            <appender-ref ref="STDOUT" />
        </appender>
        
        <logger name="play" level="INFO" />
        <root level="INFO">
            <appender-ref ref="ASYNCFILE" />
            <appender-ref ref="ASYNCSTDOUT" />
        </root>
        
    </configuration>
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: cassandra
  name: cassandra
  namespace: thehive
spec:
  ports:
    - port: 9042
  selector:
    app: cassandra
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: cassandra
  namespace: thehive
  labels:
    app: cassandra
spec:
  serviceName: cassandra
  replicas: 1
  selector:
    matchLabels:
      app: cassandra
  template:
    metadata:
      labels:
        app: cassandra
    spec:
      terminationGracePeriodSeconds: 1800
      containers:
        - name: cassandra
          image: cassandra:4.0
          ports:
            - containerPort: 7000
              name: intra-node
            - containerPort: 7001
              name: tls-intra-node
            - containerPort: 7199
              name: jmx
            - containerPort: 9042
              name: cql
          resources:
            limits:
              cpu: "500m"
              memory: 1Gi
            requests:
              cpu: "500m"
              memory: 1Gi
          securityContext:
            capabilities:
              add:
                - IPC_LOCK
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/sh
                  - -c
                  - nodetool drain
          env:
            - name: MAX_HEAP_SIZE
              value: 512M
            - name: HEAP_NEWSIZE
              value: 100M
            - name: CASSANDRA_CLUSTER_NAME
              value: "TheHive"
            - name: CASSANDRA_DC
              value: "DC1-TheHive"
            - name: CASSANDRA_RACK
              value: "Rack1-TheHive"
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
          # These volume mounts are persistent. They are like inline claims,
          # but not exactly because the names need to match exactly one of
          # the stateful pod volumes.
          volumeMounts:
            - name: cassandra-data
              mountPath: /var/lib/cassandra
      volumes:
        - name: cassandra-data
          persistentVolumeClaim:
            claimName: cassandra-pvc
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: elasticsearch
  name: elasticsearch
  namespace: thehive
spec:
  ports:
    - port: 9200
  selector:
    app: elasticsearch
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: elasticsearch
  namespace: thehive
  labels:
    app: elasticsearch
spec:
  serviceName: elasticsearch
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      labels:
        app: elasticsearch
    spec:
      terminationGracePeriodSeconds: 1800
      initContainers:
        - name: init
          image: debian:stable-slim
          command:
            - bash
            - "-c"
            - "mkdir -p /usr/share/elasticsearch/data && chmod -R 777 /usr/share/elasticsearch/data"
          volumeMounts:
            - name: es-data
              mountPath: /usr/share/elasticsearch/data
      containers:
        - name: elasticsearch
          image: docker.elastic.co/elasticsearch/elasticsearch:7.17.1
          ports:
            - containerPort: 9200
              name: http
          resources:
            limits:
              cpu: "500m"
              memory: 1Gi
            requests:
              cpu: "500m"
              memory: 512Mi
          env:
            - name: "node.name"
              value: es
            - name: "cluster.name"
              value: es-docker-cluster
            - name: "discovery.type"
              value: single-node
            - name: "bootstrap.memory_lock"
              value: "true"
            - name: ES_JAVA_OPTS
              value: "-Xms512m -Xmx512m"
            - name: "xpack.security.enabled"
              value: "false"
          volumeMounts:
            - name: es-data
              mountPath: /usr/share/elasticsearch/data
      volumes:
        - name: es-data
          emptyDir: {}